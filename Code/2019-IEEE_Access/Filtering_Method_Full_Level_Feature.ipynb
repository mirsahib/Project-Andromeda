{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,location,numOfFold):\n",
    "        self.fold = numOfFold\n",
    "        self.kFold = KFold(numOfFold,True,1)\n",
    "        self.avg_accuracy = []\n",
    "        self.data = pd.read_csv(location)\n",
    "        self.data = self.data.fillna(self.data.mean())\n",
    "        self.X = self.data.drop('label',axis=1)\n",
    "        self.Y = self.data['label']\n",
    "        print('X shape:',str(self.X.shape))\n",
    "        print('Y shape:',str(self.Y.shape))\n",
    "    def loadData(self,location,numOfFold):\n",
    "        self.fold = numOfFold\n",
    "        self.kFold = KFold(numOfFold,True,1)\n",
    "        self.avg_accuracy = []\n",
    "        self.data = pd.read_csv(location)\n",
    "        self.data = self.data.fillna(self.data.mean())\n",
    "        self.X = self.data.drop('label',axis=1)\n",
    "        self.Y = self.data['label']\n",
    "        print('X shape:',str(self.X.shape))\n",
    "        print('Y shape:',str(self.Y.shape))\n",
    "    def removeContantFeature(self):\n",
    "        #print('Removing constant feature')\n",
    "        constant_filter = VarianceThreshold(threshold=0)\n",
    "        constant_filter.fit(self.X_train)\n",
    "        #print('Number of constant feature ',constant_filter.get_support().sum())\n",
    "        constant_list = [not temp for temp in constant_filter.get_support()]\n",
    "        self.X.columns[constant_list]\n",
    "        self.X_train_filter = constant_filter.transform(self.X_train)\n",
    "        self.X_test_filter = constant_filter.transform(self.X_test)\n",
    "        print('Shape of the dataset after removal of constant features')\n",
    "        print(self.X_train_filter.shape,self.X_test_filter.shape,self.X_train.shape,'\\n')\n",
    "    def removeQuasiConstant(self):\n",
    "        #print('Removing Quasi constant feature')\n",
    "        quasi_constant_filter = VarianceThreshold(threshold = 0.01)\n",
    "        quasi_constant_filter.fit(self.X_train_filter)\n",
    "        #print('Number of quasi constant feature ',quasi_constant_filter.get_support().sum())\n",
    "        self.X_train_quasi_filter = quasi_constant_filter.transform(self.X_train_filter)\n",
    "        self.X_test_quasi_filter = quasi_constant_filter.transform(self.X_test_filter)\n",
    "        print('Shape of the dataset after removal of quasi constant features')\n",
    "        print(self.X_train_quasi_filter.shape,self.X_test_quasi_filter.shape,self.X_train.shape,'\\n')\n",
    "        \n",
    "    def removeDuplicateFeature(self):\n",
    "        X_train_T = self.X_train_quasi_filter.T\n",
    "        X_test_T = self.X_test_quasi_filter.T\n",
    "        X_train_T = pd.DataFrame(X_train_T)\n",
    "        X_test_T = pd.DataFrame(X_test_T)\n",
    "        #print('Number of duplicate feature ',X_train_T.duplicated().sum())\n",
    "        duplicated_feature = X_train_T.duplicated()\n",
    "        features_to_keep = [not index for index in duplicated_feature]\n",
    "        self.X_train_unique = X_train_T[features_to_keep].T\n",
    "        self.X_test_unique = X_test_T[features_to_keep].T\n",
    "        print('Shape of the dataset after removal of duplicate features')\n",
    "        print(self.X_train_unique.shape,self.X_test_unique.shape,self.X_train.shape,'\\n')\n",
    "    def runRandomForest(self):\n",
    "        count = 1\n",
    "        for train_index,test_index in self.kFold.split(self.data):\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.X.iloc[train_index], self.X.iloc[test_index],self.Y.iloc[train_index], self.Y.iloc[test_index]\n",
    "            #print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "            self.removeContantFeature()\n",
    "            self.removeQuasiConstant()\n",
    "            self.removeDuplicateFeature()\n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "            clf.fit(self.X_train_unique, self.y_train)\n",
    "            self.y_pred = clf.predict(self.X_test_unique)\n",
    "            accuracy = accuracy_score(self.y_test, self.y_pred)*100\n",
    "            #print('Accuracy of fold ',str(count),': ',accuracy)\n",
    "            self.avg_accuracy.append(accuracy)\n",
    "            count = count+1\n",
    "        accDF = pd.DataFrame(self.avg_accuracy,columns = ['Accuracy per fold'],index = None)\n",
    "        print(accDF)\n",
    "        print('Average accuracy of Random forest ', sum(self.avg_accuracy)/self.fold)\n",
    "            \n",
    "        return\n",
    "    def runSVM(kernelTrick):\n",
    "        count = 1\n",
    "        scaler = StandardScaler()\n",
    "        for train_index,test_index in self.kFold.split(self.data):\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.X.iloc[train_index], self.X.iloc[test_index],self.Y.iloc[train_index], self.Y.iloc[test_index]\n",
    "            #print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "            self.removeContantFeature()\n",
    "            self.removeQuasiConstant()\n",
    "            self.removeDuplicateFeature()\n",
    "            X_train_scaled = scaler.fit_transform(self.X_train_unique)\n",
    "            X_test_scaled = scaler.fit_transform(self.X_test_unique)\n",
    "            clf = SVC(kernel = kernelTrick , C = 1)\n",
    "            clf.fit(self.X_train_scaled, self.y_train)\n",
    "            self.y_pred = clf.predict(self.X_test_scaled)\n",
    "            accuracy = accuracy_score(self.y_test, self.y_pred)*100\n",
    "            print('Accuracy of fold ',str(count),': ',accuracy)\n",
    "            self.avg_accuracy.append(accuracy)\n",
    "            count = count+1\n",
    "        accDF = pd.DataFrame(self.avg_accuracy,columns = ['Accuracy per fold'],index = None)\n",
    "        print(accDF)\n",
    "        print('Average accuracy of SVM with',kernelTrick,' : ', sum(self.avg_accuracy)/self.fold)\n",
    "    def runDecisionTree(self,Criterion):\n",
    "        count = 1\n",
    "        for train_index,test_index in self.kFold.split(self.data):\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.X.iloc[train_index], self.X.iloc[test_index],self.Y.iloc[train_index], self.Y.iloc[test_index]\n",
    "            #print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "            self.removeContantFeature()\n",
    "            self.removeQuasiConstant()\n",
    "            self.removeDuplicateFeature()\n",
    "            clf = DecisionTreeClassifier(criterion = Criterion, random_state = 100,\n",
    "                               max_depth=30, min_samples_leaf=5)\n",
    "            clf.fit(self.X_train_unique, self.y_train)\n",
    "            self.y_pred = clf.predict(self.X_test_unique)\n",
    "            accuracy = accuracy_score(self.y_test, self.y_pred)*100\n",
    "            #print('Accuracy of fold ',str(count),': ',accuracy)\n",
    "            self.avg_accuracy.append(accuracy)\n",
    "            count = count+1\n",
    "        accDF = pd.DataFrame(self.avg_accuracy,columns = ['Accuracy per fold'],index = None)\n",
    "        print(accDF)\n",
    "        print('Average accuracy of Decision Tree with ',Criterion,' as criterion: ', sum(self.avg_accuracy)/self.fold)\n",
    "    def showData(self):\n",
    "        return self.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (22797, 141)\n",
      "Y shape: (22797,)\n"
     ]
    }
   ],
   "source": [
    "location = r'/home/mirsahib/Desktop/Project-Andromeda/Dataset/Fusing_Geometric_Feature_Extracted/fusing_geometric.csv'\n",
    "FilterModel = Model(location,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18237, 141) (4560, 141) (18237, 141) \n",
      "\n",
      "Number of quasi constant feature  138\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18237, 138) (4560, 138) (18237, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18237, 138) (4560, 138) (18237, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18237, 141) (4560, 141) (18237, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18237, 137) (4560, 137) (18237, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18237, 137) (4560, 137) (18237, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18238, 141) (4559, 141) (18238, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18238, 141) (4559, 141) (18238, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18238, 141) (4559, 141) (18238, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "    Accuracy\n",
      "0  89.517544\n",
      "1  89.846491\n",
      "2  90.940996\n",
      "3  89.405571\n",
      "4  89.317833\n",
      "Average accuracy of Random forest  89.80568703509157\n"
     ]
    }
   ],
   "source": [
    "FilterModel.runRandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18237, 141) (4560, 141) (18237, 141) \n",
      "\n",
      "Number of quasi constant feature  138\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18237, 138) (4560, 138) (18237, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18237, 138) (4560, 138) (18237, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18237, 141) (4560, 141) (18237, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18237, 137) (4560, 137) (18237, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18237, 137) (4560, 137) (18237, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18238, 141) (4559, 141) (18238, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18238, 141) (4559, 141) (18238, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18238, 141) (4559, 141) (18238, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "    Accuracy\n",
      "0  63.267544\n",
      "1  60.789474\n",
      "2  61.855670\n",
      "3  62.930467\n",
      "4  62.667252\n",
      "Average accuracy of Decision Tree with  gini  as criterion:  62.30208128898689\n"
     ]
    }
   ],
   "source": [
    "FilterModel.runDecisionTree('gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18237, 141) (4560, 141) (18237, 141) \n",
      "\n",
      "Number of quasi constant feature  138\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18237, 138) (4560, 138) (18237, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18237, 138) (4560, 138) (18237, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18237, 141) (4560, 141) (18237, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18237, 137) (4560, 137) (18237, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18237, 137) (4560, 137) (18237, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18238, 141) (4559, 141) (18238, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18238, 141) (4559, 141) (18238, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Number of constant feature  141\n",
      "Shape of the dataset after removal of constant features\n",
      "(18238, 141) (4559, 141) (18238, 141) \n",
      "\n",
      "Number of quasi constant feature  137\n",
      "Shape of the dataset after removal of quasi constant features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "Shape of the dataset after removal of duplicate features\n",
      "(18238, 137) (4559, 137) (18238, 141) \n",
      "\n",
      "    Accuracy\n",
      "0  63.377193\n",
      "1  64.298246\n",
      "2  63.785918\n",
      "3  63.851722\n",
      "4  61.680193\n",
      "Average accuracy of Decision Tree with  entropy  as criterion:  63.39865429091483\n"
     ]
    }
   ],
   "source": [
    "FilterModel.runDecisionTree('entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
